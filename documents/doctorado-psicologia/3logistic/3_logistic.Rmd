---
title: "Regresion Logistica"
author: ".small[Juan Carlos Castillo<br><br> Departamento de Sociología - UCH / COES <br><br>]"
date: "1er Sem 2019"
output:
  xaringan::moon_reader:
    css: ["../xaringan_custom/xaringan-themer.css","../xaringan_custom/progress-bar.css"]
    lib_dir: libs
    nature:
      slideNumberFormat:   |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>`
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "../xaringan_custom/macros.js"
    seal: false # esto omite title slide automática
---
class: bottom, left

```{r setup, include=FALSE, cache = FALSE}
require("knitr")
options(htmltools.dir.version = FALSE)
```

<!---
Para correr en ATOM
- open terminal, abrir R (simplemente, R y enter)
- Revisar si se encuentra en el directorio correcto getwd(), si no: setwd("~/Dropbox/...)
- rmarkdown::render('3_logistic.Rmd', 'xaringan::moon_reader')

About macros.js: permite escalar las imágenes como [scale 50%](path to image), hay si que grabar ese archivo js en el directorio.
--->

.right[![:scale 30%](https://escudouchile.files.wordpress.com/2012/06/logotipo-facso-ciencias-sociales-u-de-chile.png)]

<br>
<br>
<br>

# Modelos de regresión - Doctorado en Psicología 2019
<br>
## Juan Carlos Castillo

## Sesión 3: Regresión logística

---
class: inverse

# Contenidos

## 1. Introducción

## 2. Niveles de interpretación

## 3. Ajuste

---
class: roja, middle, center

# 1. Introducción

---
class: inverse, center

![:scale 45%](../images/postertitanic.jpg)

# ¿Puedes anticipar el final?

???

Si vas al cine a ver esta película, y si antes conoces los datos sobre el Titanic, puedes anticipar el final?

---
# Sobrevivientes
.center[
```{r, echo=FALSE, fig.height=6}
pacman::p_load(sjmisc, descr,tidyverse, scales, xtable, ggmosaic, stargazer)
load(url("https://juancarloscastillo.github.io/metsoc-facsouchile/documents/data/titanic.Rdata"))

(ggplot(tt, aes(survived, fill=survived))
 + geom_bar()
 + geom_text(
     aes(label = scales::percent((..count..)/sum(..count..))),
     stat='count',
      size=10,
    vjust = 3)
+ theme(legend.position="none", text = element_text(size = 30),axis.title=element_blank())
)

```
]

---
# Sexo

.center[
```{r, echo=FALSE, fig.height=6}

(ggplot(tt, aes(sex, fill=sex))
 + geom_bar()
 + geom_text(
     aes(label = scales::percent((..count..)/sum(..count..))),
     stat='count',
      size=10,
    vjust = 3)
+ theme(legend.position="none", text = element_text(size = 30),axis.title=element_blank())
)
```
]
---
## Sobrevivencia / sexo

.center[
```{r echo=FALSE, fig.height=6}
ggplot(data = tt) +
  geom_mosaic(aes(x = product(sex), fill=survived)) +
  theme(legend.position="none", text = element_text(size = 25),axis.title=element_blank())
```
]
---
# Sobrevive / Edad

.center[
```{r echo=FALSE, fig.height=6}
ggplot(tt, aes(x = age)) +
  geom_histogram(aes(color = survived, fill = survived),
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800")) +
  theme(text = element_text(size=20))
```
]

---
# Regresión

### Modelando la probabilidad de sobrevivir con regresión OLS

```{r echo=FALSE, results='hide'}
# Generar dummy sexo
str(tt$sex)

tt$sex_f<-tt$sex

tt <- tt %>% mutate(sex=recode(sex, "Hombre"=0, "Mujer"=1), label="Mujer")
str(tt$sex)
```

```{r}
reg_tit=lm(tt$survived ~ tt$sex)
```
--
 ---
**Primera advertencia**: no se puede hacer una regresión (mínimos cuadrados) con un factor como dependiente. Se puede forzar haciendo "como si" la variable fuera continua con valores 0 y 1.

```{r}
tt <- tt %>% mutate(survived_n=recode(survived,
"No sobrevive"=0, "Sobrevive"=1))
```
---
## Modelo de probabilidad lineal

.pull-left[
Se da este nombre a los modelos de regresión donde una variable dependiente dicotómica se estima de manera tradicional (mínimos cuadrados ordinarios)

```{r echo=FALSE}
reg_tit=lm(survived_n ~ sex, data=tt)
```
]
.pull-right[
.medium[
```{r results='asis', echo=FALSE}
stargazer::stargazer(reg_tit, type="html",omit.stat = c("ser", "f"))
```
]
]

---
## Significado coeficientes modelo probabilidad lineal

.center[
**Promedio de supervivencia por sexo**
```{r results='asis', echo=FALSE}
print(xtable(compmeans(tt$survived_n,tt$sex_f, plot=FALSE), digits=c(0,3,0,2)),type="html")


```
]

- El valor del intercepto=0.205 (0.21 aproximado) es el valor predicho para la categoría de referencia "hombre".

- El $\beta$ de sexo (mujer) =0.547 sumado al intercepto equivale al promedio de supervivencia de mujeres

---
## Problemas regresión lineal para dependientes dicotómicas

.center[
```{r echo=FALSE,fig.height=6}
ggplot(data = tt, aes(x = as.numeric(sex), y = survived_n)) +
  geom_point(aes(color = as.factor(survived_n)), shape = 1) +
  geom_smooth(method = "lm", color = "gray20", se = FALSE) +
  theme_bw()  +
  labs(title = "Regresión lineal por mínimos cuadrados",
       y = "Sobrevive") +
  theme(legend.position = "none", text = element_text(size = 20))
```
]

---
## Problemas ....
.medium[.center[
```{r echo=FALSE}
ggplot(data = tt, aes(x = age, y = survived_n)) +
  geom_point(aes(color = as.factor(survived_n)), shape = 1) +
  geom_smooth(method = "lm", color = "gray20", se = FALSE) +
  theme_bw()  +
  labs(title = "Regresión lineal por mínimos cuadrados",
       y = "Sobrevive") +
  theme(legend.position = "none", text = element_text(size = 20))
```
]
]
---
# Problemas ...

Si hubieran muerto todos los menores de 20 y mayores de 40 ...
.medium[.center[
```{r echo=FALSE}
tt$survived_n2 <-tt$survived_n
tt$survived_n2[tt$age>40]<-0
tt$survived_n2[tt$age<20]<-1
```

```{r echo=FALSE, fig.height=6}
ggplot(data = tt, aes(x = age, y = survived_n2)) +
  geom_point(aes(color = as.factor(survived_n2)), shape = 1) +
  geom_smooth(method = "lm", color = "gray20", se = FALSE) +
  theme_bw()  +
  labs(title = "Regresión lineal por mínimos cuadrados",
       y = "Sobrevive") +
theme(legend.position = "none", text = element_text(size = 20))
```
]
]

---
class: roja

# Problemas regresión tradicional (OLS) para dependientes dicotómicas

- ### Eventuales predicciones fuera del rango de probabilidades posibles
- ### Ajuste a los datos / residuos: ¿Es la mejor aproximación una recta?

---
class: roja, middle, right

### La regresión logística ofrece una solución a los problemas del rango de predicciones y de ajuste a los datos del modelo de probabilidad lineal

--
<br>
.center[# ¿Cómo?]

--
## Mediante una _transformación_ de la(s) variable(s) independientes a coeficientes *LOGIT*

---
## OLS vs Logit

.pull-left[
```{r echo=FALSE}
ggplot(data = tt, aes(x = age, y = survived_n2)) +
  geom_point(aes(color = as.factor(survived_n2)), shape = 1) +
  geom_smooth(method = "lm", color = "gray20", se = FALSE) +
  theme_bw()  +
  labs(title = "Regresión lineal por mínimos cuadrados",
       y = "Sobrevive") +
  theme(legend.position = "none", text = element_text(size = 20))
```
]

.pull-right[

```{r, echo=FALSE}
modelo_logistico2 <- glm(survived_n2 ~ age, data = tt, family = "binomial")
```

```{r echo=FALSE}
ggplot(data = tt, aes(x = age, y = survived_n2)) +
  geom_point(aes(color = as.factor(survived_n2)), shape = 1) +
  stat_function(fun = function(x){predict(modelo_logistico2,
                                          newdata = data.frame(age = x),
                                          type = "response")}) +
  theme_bw() +
  labs(title = "Regresión logística",
       y = "Probabilidad sobrevivir") +
  theme(legend.position = "none", text = element_text(size = 20))

```
]

---
class: roja, middle

# 2. Niveles interpretación

## A. Asociaciones e hipótesis

## B. Coeficientes y predicción

---
class: inverse, middle, center


# A. Asociaciones e hipótesis:

## H1: Las mujeres sobreviven más que los hombres

---
# Estimación en R: `glm`

Forma general:

.large[
```{r eval=FALSE}
modelo <- glm(dependiente ~ indep 1 + indep2 + ...,
          data=datos,
          family="binomial")
```
]
--

Similar a regresión OLS con `lm`, diferencias:

- `glm` (general lineal model) es la que se utiliza para variables dependientes categóricas


- `family="binomial"` indica que la dependiente es dicotómica

---
# Ejemplo Titanic

.pull-left[
```{r}
modelo_titanic <-
glm(survived ~ sex,
data = tt,
family = "binomial")
```

]
.pull-right[.small[
```{r results='asis', echo=FALSE}
stargazer(modelo_titanic, type="html")
```
]
]
---
## Interpretación de asociaciones

### - Coeficiente logit asociado a sexo (mujer) = +2.467 :
  - las mujeres tienen una mayor probabilidad de sobrevivir que los hombres.

--

## Contraste de hipótesis

- La diferencia de las probabilidades de sobrevivir entre hombres y mujeres son estadísticamente significativas, por lo que se rechaza la hipótesis nula con un nivel de probabilidad $p<0.01$.

--
### - Por lo tanto, los coeficientes _logit_ sirven en primera instancia para determinar si existe una asociación positiva o negativa


---
class: inverse, middle, center


# B. Coeficientes y predicción

<br>
## Segundo nivel de interpretación

---
## Interpretación de coeficientes

### Interpretación directa

- En el sentido más directo, por una unidad de cambio en la variable independiente, el logit (o log odds) de la variable dependiente cambia en $\beta$ unidades

- En el ejemplo, el logit de sobrevivir de las mujeres en relación a los hombres es de 2.467

--
.center[
## ¿Qué significa esto?
]
- Sustantivamente no nos dice mucho, ya que el logit es una transformación de la escala original.

- Por lo tanto, para poder interpretar el sentido del coeficiente se requiere volver a la métrica original mediante una transformación inversa.

---
## Interpretación de coeficientes

### Interpretación en términos de chances (Odds Ratio)

- Ya que el logit es el log de los OR, para transformalo a OR se debe exponenciar:

```{r}
exp(2.467)
```
### Las chances (odds) de sobrevivir siendo mujer son **11.78** veces más que las de un hombre.

---
## Odds y Logits

- Recordemos que el logit se basa en una transformación matemática de una proporción de probabilidades o **odds** (chances): probabilidad de que algo ocurra dividido por la probabilidad de que no ocurra

$$Odds=\frac{p}{1-p}$$
--
Ej. Titanic:
  - 427 sobrevivientes (41%), 619 muertos (59%)
  - $Odds_{sobrevivir}=427/619=0.41/0.59=0.69$

**Es decir, las chances de sobrevivir son de 0.69**
---
## Odds y Logits

- Odds de 1 significan chances iguales, menores a 1 son negativas y mayores a 1 son positivas

- Propiedad simétrica: un $Odd=4$ es una asociación positiva proporcional a la asociación negativa $Odd=1/4=0.25$

---
## Odds y Logits

En regresión no nos basta con los odds de una variable, sino los que reflejen asociación entre variables. Para esto se utilizan los **Odds-Ratio (OR)**

--

**¿Tienen las mujeres más chances de sobrevivir que los hombres?**

--

```{r, echo=FALSE, results='asis'}

print(xtable(prop.table(table(tt$survived,tt$sex_f),2), digits=c(0,3,3)), type="html")

```
--

$$OR=\frac{p_{m}/(1-p_{m})}{p_{h}/(1-p_{h})}=\frac{0.753/(1-0.753)}{0.205/(1-0.205)}=\frac{3.032}{0.257}=11.78$$

--
### Las chances de sobrevivir de las mujeres son **11.78** veces más que las de los hombres.

---
## Transformación a Odds


$$Odds_X=e^{\beta_0 + \beta_jX_j}$$

<br>
--
- Predicción para **mujeres**= -1.354 + (2.467 * Sexo=1) = 1.113

- Predicción para **hombres**= -1.354 + (2.467 * Sexo=0) = -1.354

--

<br>

$$Odds_{mujer}=e^{1.113}=3.032$$
$$Odds_{hombre}=e^{-1.354}=0.257$$

--
### Por lo tanto, la transformación del logit predicho mediante exponenciación permite obtener los Odds.

---
## Transformación a probabilidades predichas

$$p_{mujeres}=\frac{e^{1.113}}{1+e^{1.113}}=\frac{3.04}{4.04}=0.752$$
$$p_{hombres}=\frac{e^{-1.354}}{1+e^{-1.354}}=\frac{0.258}{1.258}=0.205$$

--

<br>
<br>

```{r, echo=FALSE, results='asis'}

print(xtable(prop.table(table(tt$survived,tt$sex_f),2), digits=c(0,3,3)), type="html")

```

---
# Resumen: ¿Qué ganamos con la regresión logística?

### A partir de la estimación logística, con los coeficientes logit podemos:

### 1. Obtener los Odds-Ratio= $e^{\beta}$

### 2. Obtener los Odds = $e^{\beta_0+\beta_X}$

### 3. Obtener las probabilidades = $\frac{e^{\beta_0+\beta_X}}{1+e^{\beta_0+\beta_X}}$

---
# Resumen: ¿Qué ganamos con la regresión logística?

### - predicción en el rango de probabilidades (0,1) (que no se logra con regresión OLS)

### - mejor ajuste mediante forma funcional curva (sigmoide)

### - posibilidad de control estadístico en logística múltiple

---
class: roja, middle, center

# 3. Ajuste

---
## Ajuste: ¿Qué tan bueno es nuestro modelo?

- El ajuste de los modelos logísticos se evalúa en general en términos comparativos con otros modelos con más/menos predictores

- Estas medidas de comparación se basan en la log verosimilitud (log-likelihood) del modelo, que es una magnitud que se obtiene dado el procedimiento de estimación en regresión logística.

- Entre las medidas de ajuste usualmente se consideran:

  - Devianza (deviance)
  - Test de razón de verosimilitud (likelihood ratio test)
  - R2s
  - Criterio de información de Akaike

---
## Devianza

- Devianza =-2*log likelihood: Se utiliza como una medida de los residuos generados por el modelo, comparando con el modelo nulo (sin predictores). En general si disminuye, el modelo es mejor

```{r}
modelo_titanic$null.deviance # devianza modelo sin predictores
modelo_titanic$deviance # devianza modelo con predictores
```
---
## Test de razón de verosimilitud

Compara las verosimilitudes del modelo con otro con menos predictores

.small[

```{r}
null_titanic=glm(survived~1, data=tt, family=binomial)

anova(modelo_titanic, null_titanic, test ="Chisq")
```

]

La diferencia entre los modelos es estadísticamente significativa con una probabilidad $p<0.01$. Por lo tanto el modelo con predictores (sexo) ofrece un mejor ajuste a los datos que un modelo sin predictores.

---
#  McFadden (pseudo) R2

Se define como: $1−[LL(LM)/LL(L0)]$, donde

- LL es el log likelihood del modelo
- LM es el modelo posterior (con predictores)
- L0 es el modelo nulo

--

.small[
```{r}
logLik(modelo_titanic); logLik(null_titanic)
1-(-551/-707)
```

]

--

También se puede obtener con la función `PseudoR2` de la librería `DescTools`, junto a otras versiones de pseudo R2s, como "Nagelkerke", "CoxSnell" y "Effron".


---
## Akaike (AIC)

AIC - Akaike information criteria, evalua la calidad del modelo a través de la comparación con otros modelos penalizando por la inclusión de predictores (análogo al R2 ajustado):

$$AIC=-2(log-likelihood)+2K$$

Donde K= número de parámetros del modelo (regresores + intercepto)

.small[
```{r}
logLik(modelo_titanic)

2*551

```
$$AIC=-2(-551)+2(2)=1102+4=1106$$

En sí mismo no es interpretable, solo como criterio comparativo: menor AIC es mejor fit.
]
---
class: roja, right

# RESUMEN

### Limitaciones de regresión tradicional (OLS) para variables dependientes dicotómicas

### Dos niveles de interpretación de regresión logística: asociaciones y coeficientes

### Ajuste: medidas comparativas basadas en la log-verosimilitud de los modelos


---
class: bottom, left

.right[![:scale 30%](https://escudouchile.files.wordpress.com/2012/06/logotipo-facso-ciencias-sociales-u-de-chile.png)]

<br>
<br>
<br>
<br>
<br>
<br>
<br>

## Juan Carlos Castillo

## **Sesión 3**: Regresión Logística
